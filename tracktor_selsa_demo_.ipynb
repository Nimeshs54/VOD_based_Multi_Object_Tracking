{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9dc461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nimesh/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/nimesh/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/__init__.py:21: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  'On January 1, 2023, MMCV will release v2.0.0, in which it will remove '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    detector=dict(\n",
      "        type='FasterRCNN',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(3, ),\n",
      "            strides=(1, 2, 2, 1),\n",
      "            dilations=(1, 1, 1, 2),\n",
      "            frozen_stages=1,\n",
      "            norm_cfg=dict(type='BN', requires_grad=True),\n",
      "            norm_eval=True,\n",
      "            style='pytorch',\n",
      "            init_cfg=dict(\n",
      "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "        neck=dict(\n",
      "            type='ChannelMapper',\n",
      "            in_channels=[2048],\n",
      "            out_channels=512,\n",
      "            kernel_size=3),\n",
      "        rpn_head=dict(\n",
      "            type='RPNHead',\n",
      "            in_channels=512,\n",
      "            feat_channels=512,\n",
      "            anchor_generator=dict(\n",
      "                type='AnchorGenerator',\n",
      "                scales=[4, 8, 16, 32],\n",
      "                ratios=[0.5, 1.0, 2.0],\n",
      "                strides=[16]),\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "            loss_bbox=dict(\n",
      "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
      "                loss_weight=1.0)),\n",
      "        roi_head=dict(\n",
      "            type='SelsaRoIHead',\n",
      "            bbox_roi_extractor=dict(\n",
      "                type='SingleRoIExtractor',\n",
      "                roi_layer=dict(\n",
      "                    type='RoIAlign', output_size=7, sampling_ratio=2),\n",
      "                out_channels=512,\n",
      "                featmap_strides=[16]),\n",
      "            bbox_head=dict(\n",
      "                type='SelsaBBoxHead',\n",
      "                in_channels=512,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=1,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.2, 0.2, 0.2, 0.2]),\n",
      "                reg_class_agnostic=False,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0),\n",
      "                num_shared_fcs=2,\n",
      "                aggregator=dict(\n",
      "                    type='SelsaAggregator',\n",
      "                    in_channels=1024,\n",
      "                    num_attention_blocks=16))),\n",
      "        train_cfg=dict(\n",
      "            rpn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.3,\n",
      "                    min_pos_iou=0.3,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=256,\n",
      "                    pos_fraction=0.5,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=False),\n",
      "                allowed_border=0,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            rpn_proposal=dict(\n",
      "                nms_pre=6000,\n",
      "                max_per_img=600,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=256,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)),\n",
      "        test_cfg=dict(\n",
      "            rpn=dict(\n",
      "                nms_pre=6000,\n",
      "                max_per_img=300,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                score_thr=0.0001,\n",
      "                nms=dict(type='nms', iou_threshold=0.5),\n",
      "                max_per_img=100))),\n",
      "    type='SELSA')\n",
      "dataset_type = 'MOTChallengeDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "    dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
      "    dict(\n",
      "        type='SeqResize',\n",
      "        img_scale=(1088, 1088),\n",
      "        share_params=True,\n",
      "        ratio_range=(0.8, 1.2),\n",
      "        keep_ratio=True,\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
      "    dict(\n",
      "        type='SeqRandomCrop',\n",
      "        share_params=False,\n",
      "        crop_size=(1088, 1088),\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='SeqNormalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='SeqPad', size_divisor=32),\n",
      "    dict(type='MatchInstances', skip_nomatch=True),\n",
      "    dict(\n",
      "        type='VideoCollect',\n",
      "        keys=[\n",
      "            'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
      "            'gt_instance_ids'\n",
      "        ]),\n",
      "    dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1088, 1088),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='VideoCollect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data_root = 'data/MOT17_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        visibility_thr=-1,\n",
      "        ann_file='data/MOT17_tiny/annotations/half-train_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        ref_img_sampler=dict(\n",
      "            num_ref_imgs=2,\n",
      "            frame_range=9,\n",
      "            filter_key_img=True,\n",
      "            method='bilateral_uniform'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "            dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
      "            dict(\n",
      "                type='SeqResize',\n",
      "                img_scale=(1088, 1088),\n",
      "                share_params=True,\n",
      "                ratio_range=(0.8, 1.2),\n",
      "                keep_ratio=True,\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
      "            dict(\n",
      "                type='SeqRandomCrop',\n",
      "                share_params=False,\n",
      "                crop_size=(1088, 1088),\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='SeqNormalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='SeqPad', size_divisor=32),\n",
      "            dict(type='MatchInstances', skip_nomatch=True),\n",
      "            dict(\n",
      "                type='VideoCollect',\n",
      "                keys=[\n",
      "                    'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
      "                    'gt_instance_ids'\n",
      "                ]),\n",
      "            dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        ref_img_sampler=dict(\n",
      "            num_ref_imgs=14,\n",
      "            frame_range=[-7, 7],\n",
      "            method='test_with_adaptive_stride'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='VideoCollect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        ref_img_sampler=dict(\n",
      "            num_ref_imgs=14,\n",
      "            frame_range=[-7, 7],\n",
      "            method='test_with_adaptive_stride'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='VideoCollect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.3333333333333333,\n",
      "    step=[2, 5])\n",
      "total_epochs = 7\n",
      "evaluation = dict(metric=['bbox'], interval=7)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/vid/selsa/selsa_faster_rcnn_mot17.py')\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b2f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac209914",
   "metadata": {},
   "source": [
    "# Train a detector for MOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cacdb89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "812aabff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    detector=dict(\n",
      "        type='FasterRCNN',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(3, ),\n",
      "            strides=(1, 2, 2, 1),\n",
      "            dilations=(1, 1, 1, 2),\n",
      "            frozen_stages=1,\n",
      "            norm_cfg=dict(type='BN', requires_grad=True),\n",
      "            norm_eval=True,\n",
      "            style='pytorch',\n",
      "            init_cfg=dict(\n",
      "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "        neck=dict(\n",
      "            type='ChannelMapper',\n",
      "            in_channels=[2048],\n",
      "            out_channels=512,\n",
      "            kernel_size=3),\n",
      "        rpn_head=dict(\n",
      "            type='RPNHead',\n",
      "            in_channels=512,\n",
      "            feat_channels=512,\n",
      "            anchor_generator=dict(\n",
      "                type='AnchorGenerator',\n",
      "                scales=[4, 8, 16, 32],\n",
      "                ratios=[0.5, 1.0, 2.0],\n",
      "                strides=[16]),\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "            loss_bbox=dict(\n",
      "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
      "                loss_weight=1.0)),\n",
      "        roi_head=dict(\n",
      "            type='SelsaRoIHead',\n",
      "            bbox_roi_extractor=dict(\n",
      "                type='SingleRoIExtractor',\n",
      "                roi_layer=dict(\n",
      "                    type='RoIAlign', output_size=7, sampling_ratio=2),\n",
      "                out_channels=512,\n",
      "                featmap_strides=[16]),\n",
      "            bbox_head=dict(\n",
      "                type='SelsaBBoxHead',\n",
      "                in_channels=512,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=1,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.2, 0.2, 0.2, 0.2]),\n",
      "                reg_class_agnostic=False,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0),\n",
      "                num_shared_fcs=2,\n",
      "                aggregator=dict(\n",
      "                    type='SelsaAggregator',\n",
      "                    in_channels=1024,\n",
      "                    num_attention_blocks=16))),\n",
      "        train_cfg=dict(\n",
      "            rpn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.3,\n",
      "                    min_pos_iou=0.3,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=256,\n",
      "                    pos_fraction=0.5,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=False),\n",
      "                allowed_border=0,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            rpn_proposal=dict(\n",
      "                nms_pre=6000,\n",
      "                max_per_img=600,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=256,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)),\n",
      "        test_cfg=dict(\n",
      "            rpn=dict(\n",
      "                nms_pre=6000,\n",
      "                max_per_img=300,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                score_thr=0.0001,\n",
      "                nms=dict(type='nms', iou_threshold=0.5),\n",
      "                max_per_img=100))),\n",
      "    type='SELSA')\n",
      "dataset_type = 'MOTChallengeDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "    dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
      "    dict(\n",
      "        type='SeqResize',\n",
      "        img_scale=(1088, 1088),\n",
      "        share_params=True,\n",
      "        ratio_range=(0.8, 1.2),\n",
      "        keep_ratio=True,\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
      "    dict(\n",
      "        type='SeqRandomCrop',\n",
      "        share_params=False,\n",
      "        crop_size=(1088, 1088),\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='SeqNormalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='SeqPad', size_divisor=32),\n",
      "    dict(type='MatchInstances', skip_nomatch=True),\n",
      "    dict(\n",
      "        type='VideoCollect',\n",
      "        keys=[\n",
      "            'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
      "            'gt_instance_ids'\n",
      "        ]),\n",
      "    dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1088, 1088),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='VideoCollect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data_root = 'data/MOT17_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        visibility_thr=-1,\n",
      "        ann_file='data/MOT17_tiny/annotations/half-train_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        ref_img_sampler=dict(\n",
      "            num_ref_imgs=2,\n",
      "            frame_range=9,\n",
      "            filter_key_img=True,\n",
      "            method='bilateral_uniform'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "            dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
      "            dict(\n",
      "                type='SeqResize',\n",
      "                img_scale=(1088, 1088),\n",
      "                share_params=True,\n",
      "                ratio_range=(0.8, 1.2),\n",
      "                keep_ratio=True,\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
      "            dict(\n",
      "                type='SeqRandomCrop',\n",
      "                share_params=False,\n",
      "                crop_size=(1088, 1088),\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='SeqNormalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='SeqPad', size_divisor=32),\n",
      "            dict(type='MatchInstances', skip_nomatch=True),\n",
      "            dict(\n",
      "                type='VideoCollect',\n",
      "                keys=[\n",
      "                    'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
      "                    'gt_instance_ids'\n",
      "                ]),\n",
      "            dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        ref_img_sampler=dict(\n",
      "            num_ref_imgs=14,\n",
      "            frame_range=[-7, 7],\n",
      "            method='test_with_adaptive_stride'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='VideoCollect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        ref_img_sampler=dict(\n",
      "            num_ref_imgs=14,\n",
      "            frame_range=[-7, 7],\n",
      "            method='test_with_adaptive_stride'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='VideoCollect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.3333333333333333,\n",
      "    step=[2, 5])\n",
      "total_epochs = 7\n",
      "evaluation = dict(metric=['bbox'], interval=7)\n",
      "work_dir = './tut_mot_vid/detector'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import mmcv\n",
    "# from mmdet.apis import set_random_seed\n",
    "# cfg = mmcv.Config.fromfile('./configs/mot/mytracktor/mytracktor_selsa_r50_dc5_mot15-private-half.py')\n",
    "# # cfg.data_root = 'data/MOT17_tiny/'\n",
    "# # cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "# # cfg.data.train.ann_file = cfg.data.train.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "# # cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "# # cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "# # cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "# # cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "# cfg.work_dir = './tutorial_exps_mot_vid/detector'\n",
    "# cfg.seed = 0\n",
    "# set_random_seed(0, deterministic=False)\n",
    "# cfg.gpu_ids = range(1)\n",
    "# print(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/vid/selsa/selsa_faster_rcnn_mot17.py')\n",
    "# cfg.data_root = 'data/MOT17_tiny/'\n",
    "# cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "# cfg.data.train.ann_file = cfg.data.train.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "# cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "# cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "# cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "# cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "cfg.work_dir = './tut_mot_vid/detector'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90de154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing BURST due to missing underlying dependency: No module named 'tabulate'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"FasterRCNN: 'SelsaRoIHead is not in the models registry'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmdet/models/detectors/faster_rcnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, backbone, rpn_head, roi_head, train_cfg, test_cfg, neck, pretrained, init_cfg)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             init_cfg=init_cfg)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmdet/models/detectors/two_stage.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, backbone, neck, rpn_head, roi_head, train_cfg, test_cfg, pretrained, init_cfg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mroi_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmdet/models/builder.py\u001b[0m in \u001b[0;36mbuild_head\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Build head.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mHEADS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/cnn/builder.py\u001b[0m in \u001b[0;36mbuild_model_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_from_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     61\u001b[0m             raise KeyError(\n\u001b[0;32m---> 62\u001b[0;31m                 f'{obj_type} is not in the {registry.name} registry')\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SelsaRoIHead is not in the models registry'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2942804/3245778930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir_or_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmdet/models/builder.py\u001b[0m in \u001b[0;36mbuild_detector\u001b[0;34m(cfg, train_cfg, test_cfg)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;34m'test_cfg specified in both outer field and model field '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     return DETECTORS.build(\n\u001b[0;32m---> 59\u001b[0;31m         cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/cnn/builder.py\u001b[0m in \u001b[0;36mbuild_model_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_from_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Normal TypeError does not print class name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{obj_cls.__name__}: {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"FasterRCNN: 'SelsaRoIHead is not in the models registry'\""
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmtrack.datasets import build_dataset\n",
    "from mmdet.apis import train_detector as train_model\n",
    "from mmdet.models import build_detector as build_model\n",
    "\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "model = build_model(cfg.model.detector)\n",
    "model.init_weights()\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "cfg.device='cuda' \n",
    "train_model(model, datasets, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa942f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf8cb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    detector=dict(\n",
      "        type='FasterRCNN',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(0, 1, 2, 3),\n",
      "            frozen_stages=1,\n",
      "            norm_cfg=dict(type='BN', requires_grad=True),\n",
      "            norm_eval=True,\n",
      "            style='pytorch',\n",
      "            init_cfg=dict(\n",
      "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "        neck=dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            num_outs=5),\n",
      "        rpn_head=dict(\n",
      "            type='RPNHead',\n",
      "            in_channels=256,\n",
      "            feat_channels=256,\n",
      "            anchor_generator=dict(\n",
      "                type='AnchorGenerator',\n",
      "                scales=[8],\n",
      "                ratios=[0.5, 1.0, 2.0],\n",
      "                strides=[4, 8, 16, 32, 64]),\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[1.0, 1.0, 1.0, 1.0],\n",
      "                clip_border=False),\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "            loss_bbox=dict(\n",
      "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
      "                loss_weight=1.0)),\n",
      "        roi_head=dict(\n",
      "            type='StandardRoIHead',\n",
      "            bbox_roi_extractor=dict(\n",
      "                type='SingleRoIExtractor',\n",
      "                roi_layer=dict(\n",
      "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "                out_channels=256,\n",
      "                featmap_strides=[4, 8, 16, 32]),\n",
      "            bbox_head=dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=1,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2],\n",
      "                    clip_border=False),\n",
      "                reg_class_agnostic=False,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
      "        train_cfg=dict(\n",
      "            rpn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.3,\n",
      "                    min_pos_iou=0.3,\n",
      "                    match_low_quality=True,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=256,\n",
      "                    pos_fraction=0.5,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=False),\n",
      "                allowed_border=-1,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            rpn_proposal=dict(\n",
      "                nms_pre=2000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)),\n",
      "        test_cfg=dict(\n",
      "            rpn=dict(\n",
      "                nms_pre=1000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                score_thr=0.05,\n",
      "                nms=dict(type='nms', iou_threshold=0.5),\n",
      "                max_per_img=100)),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'\n",
      "        )))\n",
      "dataset_type = 'CocoDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', to_float32=True),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=(1088, 1088),\n",
      "        ratio_range=(0.8, 1.2),\n",
      "        keep_ratio=True,\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='RandomCrop', crop_size=(1088, 1088), bbox_clip_border=False),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1088, 1088),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data_root = 'data/MOT17_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-train_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        classes=('pedestrian', ),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=(1088, 1088),\n",
      "                ratio_range=(0.8, 1.2),\n",
      "                keep_ratio=True,\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='RandomCrop',\n",
      "                crop_size=(1088, 1088),\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        classes=('pedestrian', ),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        classes=('pedestrian', ),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(metric=['bbox'])\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "USE_MMDET = True\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=100,\n",
      "    warmup_ratio=0.01,\n",
      "    step=[3])\n",
      "total_epochs = 4\n",
      "work_dir = './tutorial_exps/detector'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/det/faster-rcnn_r50_fpn_4e_mot17-half.py')\n",
    "cfg.data_root = 'data/MOT17_tiny/'\n",
    "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.ann_file = cfg.data.train.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "cfg.work_dir = './tutorial_exps/detector'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3adfe286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing BURST due to missing underlying dependency: No module named 'tabulate'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 04:13:56,607 - mmcv - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': 'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'}\n",
      "[06/05 04:13:56] mmcv INFO: initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': 'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'}\n",
      "2023-06-05 04:13:56,608 - mmcv - INFO - load model from: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "[06/05 04:13:56] mmcv INFO: load model from: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "2023-06-05 04:13:56,609 - mmcv - INFO - load checkpoint from http path: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "[06/05 04:13:56] mmcv INFO: load checkpoint from http path: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "2023-06-05 04:13:56,706 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([4]).\n",
      "[06/05 04:13:56] mmcv WARNING: The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([4]).\n",
      "/home/nimesh/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmdet/utils/compat_config.py:30: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\n",
      "  'please set `runner` in your config.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 04:13:58,956 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2023-06-05 04:13:58,957 - mmdet - INFO - Start running, host: nimesh@mindgarage26, work_dir: /home/nimesh/mmtracking/tutorial_exps/detector\n",
      "2023-06-05 04:13:58,958 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2023-06-05 04:13:58,959 - mmdet - INFO - workflow: [('train', 1)], max: 4 epochs\n",
      "2023-06-05 04:13:58,959 - mmdet - INFO - Checkpoints will be saved to /home/nimesh/mmtracking/tutorial_exps/detector by HardDiskBackend.\n",
      "/home/nimesh/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "2023-06-05 04:14:13,823 - mmdet - INFO - Epoch [1][50/414]\tlr: 9.902e-03, eta: 0:07:55, time: 0.296, data_time: 0.048, memory: 2942, loss_rpn_cls: 0.0943, loss_rpn_bbox: 0.1175, loss_cls: 0.4032, acc: 81.0977, loss_bbox: 0.3385, loss: 0.9535\n",
      "2023-06-05 04:14:26,419 - mmdet - INFO - Epoch [1][100/414]\tlr: 1.980e-02, eta: 0:07:06, time: 0.252, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0469, loss_rpn_bbox: 0.1270, loss_cls: 0.3260, acc: 86.1016, loss_bbox: 0.2393, loss: 0.7392\n",
      "2023-06-05 04:14:39,187 - mmdet - INFO - Epoch [1][150/414]\tlr: 2.000e-02, eta: 0:06:43, time: 0.256, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0342, loss_rpn_bbox: 0.1046, loss_cls: 0.2950, acc: 87.5742, loss_bbox: 0.2154, loss: 0.6492\n",
      "2023-06-05 04:14:52,040 - mmdet - INFO - Epoch [1][200/414]\tlr: 2.000e-02, eta: 0:06:25, time: 0.257, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0248, loss_rpn_bbox: 0.0829, loss_cls: 0.2606, acc: 88.8242, loss_bbox: 0.1818, loss: 0.5500\n",
      "2023-06-05 04:15:04,860 - mmdet - INFO - Epoch [1][250/414]\tlr: 2.000e-02, eta: 0:06:10, time: 0.256, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0242, loss_rpn_bbox: 0.0754, loss_cls: 0.2576, acc: 88.7578, loss_bbox: 0.1773, loss: 0.5344\n",
      "2023-06-05 04:15:17,517 - mmdet - INFO - Epoch [1][300/414]\tlr: 2.000e-02, eta: 0:05:54, time: 0.253, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0180, loss_rpn_bbox: 0.0715, loss_cls: 0.2568, acc: 88.8379, loss_bbox: 0.1872, loss: 0.5335\n",
      "2023-06-05 04:15:30,312 - mmdet - INFO - Epoch [1][350/414]\tlr: 2.000e-02, eta: 0:05:40, time: 0.256, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0186, loss_rpn_bbox: 0.0663, loss_cls: 0.2374, acc: 89.8945, loss_bbox: 0.1647, loss: 0.4870\n",
      "2023-06-05 04:15:43,102 - mmdet - INFO - Epoch [1][400/414]\tlr: 2.000e-02, eta: 0:05:26, time: 0.256, data_time: 0.005, memory: 2942, loss_rpn_cls: 0.0142, loss_rpn_bbox: 0.0614, loss_cls: 0.2174, acc: 90.7344, loss_bbox: 0.1472, loss: 0.4402\n",
      "2023-06-05 04:15:46,568 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
      "2023-06-05 04:16:02,204 - mmdet - INFO - Epoch [2][50/414]\tlr: 2.000e-02, eta: 0:05:05, time: 0.298, data_time: 0.049, memory: 2942, loss_rpn_cls: 0.0127, loss_rpn_bbox: 0.0583, loss_cls: 0.2096, acc: 91.0723, loss_bbox: 0.1456, loss: 0.4262\n",
      "2023-06-05 04:16:15,007 - mmdet - INFO - Epoch [2][100/414]\tlr: 2.000e-02, eta: 0:04:52, time: 0.256, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0134, loss_rpn_bbox: 0.0671, loss_cls: 0.2142, acc: 90.8359, loss_bbox: 0.1412, loss: 0.4359\n",
      "2023-06-05 04:16:27,861 - mmdet - INFO - Epoch [2][150/414]\tlr: 2.000e-02, eta: 0:04:40, time: 0.257, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0137, loss_rpn_bbox: 0.0607, loss_cls: 0.2043, acc: 91.2051, loss_bbox: 0.1371, loss: 0.4159\n",
      "2023-06-05 04:16:40,767 - mmdet - INFO - Epoch [2][200/414]\tlr: 2.000e-02, eta: 0:04:27, time: 0.258, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0137, loss_rpn_bbox: 0.0602, loss_cls: 0.1953, acc: 91.5703, loss_bbox: 0.1339, loss: 0.4031\n",
      "2023-06-05 04:16:53,620 - mmdet - INFO - Epoch [2][250/414]\tlr: 2.000e-02, eta: 0:04:14, time: 0.257, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0115, loss_rpn_bbox: 0.0659, loss_cls: 0.2021, acc: 91.3984, loss_bbox: 0.1372, loss: 0.4167\n",
      "2023-06-05 04:17:06,458 - mmdet - INFO - Epoch [2][300/414]\tlr: 2.000e-02, eta: 0:04:01, time: 0.257, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0141, loss_rpn_bbox: 0.0484, loss_cls: 0.1863, acc: 92.0117, loss_bbox: 0.1283, loss: 0.3771\n",
      "2023-06-05 04:17:19,290 - mmdet - INFO - Epoch [2][350/414]\tlr: 2.000e-02, eta: 0:03:48, time: 0.257, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0105, loss_rpn_bbox: 0.0518, loss_cls: 0.1854, acc: 92.1738, loss_bbox: 0.1253, loss: 0.3730\n",
      "2023-06-05 04:17:32,008 - mmdet - INFO - Epoch [2][400/414]\tlr: 2.000e-02, eta: 0:03:35, time: 0.255, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0097, loss_rpn_bbox: 0.0491, loss_cls: 0.1794, acc: 92.4258, loss_bbox: 0.1220, loss: 0.3602\n",
      "2023-06-05 04:17:35,498 - mmdet - INFO - Saving checkpoint at 2 epochs\n",
      "2023-06-05 04:17:51,119 - mmdet - INFO - Epoch [3][50/414]\tlr: 2.000e-02, eta: 0:03:18, time: 0.297, data_time: 0.049, memory: 2942, loss_rpn_cls: 0.0083, loss_rpn_bbox: 0.0422, loss_cls: 0.1576, acc: 93.4102, loss_bbox: 0.1063, loss: 0.3144\n",
      "2023-06-05 04:18:03,956 - mmdet - INFO - Epoch [3][100/414]\tlr: 2.000e-02, eta: 0:03:05, time: 0.257, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0425, loss_cls: 0.1723, acc: 92.6406, loss_bbox: 0.1189, loss: 0.3425\n",
      "2023-06-05 04:18:16,900 - mmdet - INFO - Epoch [3][150/414]\tlr: 2.000e-02, eta: 0:02:52, time: 0.259, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0095, loss_rpn_bbox: 0.0457, loss_cls: 0.1757, acc: 92.4570, loss_bbox: 0.1111, loss: 0.3421\n",
      "2023-06-05 04:18:29,711 - mmdet - INFO - Epoch [3][200/414]\tlr: 2.000e-02, eta: 0:02:40, time: 0.256, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0085, loss_rpn_bbox: 0.0481, loss_cls: 0.1625, acc: 93.0762, loss_bbox: 0.1134, loss: 0.3325\n",
      "2023-06-05 04:18:42,514 - mmdet - INFO - Epoch [3][250/414]\tlr: 2.000e-02, eta: 0:02:27, time: 0.256, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0097, loss_rpn_bbox: 0.0406, loss_cls: 0.1686, acc: 92.9004, loss_bbox: 0.1133, loss: 0.3321\n",
      "2023-06-05 04:18:55,265 - mmdet - INFO - Epoch [3][300/414]\tlr: 2.000e-02, eta: 0:02:14, time: 0.255, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0100, loss_rpn_bbox: 0.0473, loss_cls: 0.1633, acc: 93.0566, loss_bbox: 0.1101, loss: 0.3306\n",
      "2023-06-05 04:19:08,099 - mmdet - INFO - Epoch [3][350/414]\tlr: 2.000e-02, eta: 0:02:01, time: 0.257, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0089, loss_rpn_bbox: 0.0439, loss_cls: 0.1528, acc: 93.6172, loss_bbox: 0.0997, loss: 0.3052\n",
      "2023-06-05 04:19:20,929 - mmdet - INFO - Epoch [3][400/414]\tlr: 2.000e-02, eta: 0:01:49, time: 0.257, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0442, loss_cls: 0.1579, acc: 93.1895, loss_bbox: 0.1092, loss: 0.3170\n",
      "2023-06-05 04:19:24,429 - mmdet - INFO - Saving checkpoint at 3 epochs\n",
      "2023-06-05 04:19:40,029 - mmdet - INFO - Epoch [4][50/414]\tlr: 2.000e-03, eta: 0:01:32, time: 0.297, data_time: 0.048, memory: 2942, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0322, loss_cls: 0.1364, acc: 94.2070, loss_bbox: 0.0907, loss: 0.2645\n",
      "2023-06-05 04:19:52,844 - mmdet - INFO - Epoch [4][100/414]\tlr: 2.000e-03, eta: 0:01:19, time: 0.256, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0263, loss_cls: 0.1290, acc: 94.5195, loss_bbox: 0.0817, loss: 0.2420\n",
      "2023-06-05 04:20:05,783 - mmdet - INFO - Epoch [4][150/414]\tlr: 2.000e-03, eta: 0:01:07, time: 0.259, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0275, loss_cls: 0.1256, acc: 94.6445, loss_bbox: 0.0837, loss: 0.2428\n",
      "2023-06-05 04:20:18,669 - mmdet - INFO - Epoch [4][200/414]\tlr: 2.000e-03, eta: 0:00:54, time: 0.258, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0288, loss_cls: 0.1334, acc: 94.4414, loss_bbox: 0.0903, loss: 0.2574\n",
      "2023-06-05 04:20:31,588 - mmdet - INFO - Epoch [4][250/414]\tlr: 2.000e-03, eta: 0:00:41, time: 0.258, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0283, loss_cls: 0.1330, acc: 94.4434, loss_bbox: 0.0881, loss: 0.2537\n",
      "2023-06-05 04:20:44,435 - mmdet - INFO - Epoch [4][300/414]\tlr: 2.000e-03, eta: 0:00:29, time: 0.257, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0270, loss_cls: 0.1264, acc: 94.6621, loss_bbox: 0.0839, loss: 0.2409\n",
      "2023-06-05 04:20:57,241 - mmdet - INFO - Epoch [4][350/414]\tlr: 2.000e-03, eta: 0:00:16, time: 0.256, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0260, loss_cls: 0.1207, acc: 94.9355, loss_bbox: 0.0819, loss: 0.2325\n",
      "2023-06-05 04:21:10,037 - mmdet - INFO - Epoch [4][400/414]\tlr: 2.000e-03, eta: 0:00:03, time: 0.256, data_time: 0.006, memory: 2942, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0259, loss_cls: 0.1164, acc: 95.1426, loss_bbox: 0.0788, loss: 0.2245\n",
      "2023-06-05 04:21:13,521 - mmdet - INFO - Saving checkpoint at 4 epochs\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmtrack.datasets import build_dataset\n",
    "from mmdet.apis import train_detector as train_model\n",
    "from mmdet.models import build_detector as build_model\n",
    "\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "model = build_model(cfg.model.detector)\n",
    "model.init_weights()\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "cfg.device='cuda'\n",
    "train_model(model, datasets, cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d68745b5",
   "metadata": {},
   "source": [
    "# Train a ReID model for MOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c30a5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "dataset_type = 'ReIDDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "    dict(\n",
      "        type='SeqResize',\n",
      "        img_scale=(128, 256),\n",
      "        share_params=False,\n",
      "        keep_ratio=False,\n",
      "        bbox_clip_border=False,\n",
      "        override=False),\n",
      "    dict(\n",
      "        type='SeqRandomFlip',\n",
      "        share_params=False,\n",
      "        flip_ratio=0.5,\n",
      "        direction='horizontal'),\n",
      "    dict(\n",
      "        type='SeqNormalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='VideoCollect', keys=['img', 'gt_label']),\n",
      "    dict(type='ReIDFormatBundle')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='ImageToTensor', keys=['img']),\n",
      "    dict(type='Collect', keys=['img'], meta_keys=[])\n",
      "]\n",
      "data_root = 'data/MOT17_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='ReIDDataset',\n",
      "        triplet_sampler=dict(num_ids=8, ins_per_id=4),\n",
      "        data_prefix='data/MOT17_tiny/reid/imgs',\n",
      "        ann_file='data/MOT17_tiny/reid/meta/train_9.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "            dict(\n",
      "                type='SeqResize',\n",
      "                img_scale=(128, 256),\n",
      "                share_params=False,\n",
      "                keep_ratio=False,\n",
      "                bbox_clip_border=False,\n",
      "                override=False),\n",
      "            dict(\n",
      "                type='SeqRandomFlip',\n",
      "                share_params=False,\n",
      "                flip_ratio=0.5,\n",
      "                direction='horizontal'),\n",
      "            dict(\n",
      "                type='SeqNormalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='VideoCollect', keys=['img', 'gt_label']),\n",
      "            dict(type='ReIDFormatBundle')\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='ReIDDataset',\n",
      "        triplet_sampler=None,\n",
      "        data_prefix='data/MOT17_tiny/reid/imgs',\n",
      "        ann_file='data/MOT17_tiny/reid/meta/val_20.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'], meta_keys=[])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='ReIDDataset',\n",
      "        triplet_sampler=None,\n",
      "        data_prefix='data/MOT17_tiny/reid/imgs',\n",
      "        ann_file='data/MOT17_tiny/reid/meta/val_20.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'], meta_keys=[])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "TRAIN_REID = True\n",
      "model = dict(\n",
      "    reid=dict(\n",
      "        type='BaseReID',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(3, ),\n",
      "            style='pytorch'),\n",
      "        neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
      "        head=dict(\n",
      "            type='LinearReIDHead',\n",
      "            num_fcs=1,\n",
      "            in_channels=2048,\n",
      "            fc_channels=1024,\n",
      "            out_channels=128,\n",
      "            num_classes=380,\n",
      "            loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
      "            loss_pairwise=dict(\n",
      "                type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
      "            norm_cfg=dict(type='BN1d'),\n",
      "            act_cfg=dict(type='ReLU')),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth'\n",
      "        )))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=200,\n",
      "    warmup_ratio=0.005,\n",
      "    step=[1])\n",
      "total_epochs = 2\n",
      "work_dir = './tutorial_exps/reid'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/reid/resnet50_b32x8_MOT17.py')\n",
    "cfg.data_root = 'data/MOT17_tiny/'\n",
    "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.ann_file = 'data/MOT17_tiny/reid/meta/train_9.txt'\n",
    "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "cfg.data.test.data_prefix = cfg.data.test.data_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.data_prefix = cfg.data.train.data_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.val.data_prefix = cfg.data.val.data_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "# learning policy\n",
    "cfg.lr_config = dict(\n",
    "    policy='step',\n",
    "    warmup='linear',\n",
    "    warmup_iters=200,\n",
    "    warmup_ratio=1.0 / 200,\n",
    "    step=[1])\n",
    "cfg.total_epochs = 2\n",
    "\n",
    "cfg.work_dir = './tutorial_exps/reid'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18dcd87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 04:40:39,701 - mmcv - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth'}\n",
      "2023-06-05 04:40:39,702 - mmcv - INFO - load model from: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n",
      "2023-06-05 04:40:39,702 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\" to /home/nimesh/.cache/torch/hub/checkpoints/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n",
      "100%|██████████| 97.7M/97.7M [00:03<00:00, 27.8MB/s]\n",
      "2023-06-05 04:40:43,871 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: head.fc.weight, head.fc.bias\n",
      "\n",
      "missing keys in source state_dict: head.fcs.0.fc.weight, head.fcs.0.fc.bias, head.fcs.0.bn.weight, head.fcs.0.bn.bias, head.fcs.0.bn.running_mean, head.fcs.0.bn.running_var, head.fc_out.weight, head.fc_out.bias, head.bn.weight, head.bn.bias, head.bn.running_mean, head.bn.running_var, head.classifier.weight, head.classifier.bias\n",
      "\n",
      "2023-06-05 04:40:43,933 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2023-06-05 04:40:43,935 - mmdet - INFO - Start running, host: nimesh@mindgarage26, work_dir: /home/nimesh/mmtracking/tutorial_exps/reid\n",
      "2023-06-05 04:40:43,935 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2023-06-05 04:40:43,935 - mmdet - INFO - workflow: [('train', 1)], max: 2 epochs\n",
      "2023-06-05 04:40:43,936 - mmdet - INFO - Checkpoints will be saved to /home/nimesh/mmtracking/tutorial_exps/reid by HardDiskBackend.\n",
      "2023-06-05 04:40:52,386 - mmdet - INFO - Epoch [1][50/1576]\tlr: 2.488e-02, eta: 0:08:41, time: 0.168, data_time: 0.048, memory: 2942, triplet_loss: 0.0943, ce_loss: 0.8311, top-1: 90.6250, loss: 0.9254\n",
      "2023-06-05 04:40:58,525 - mmdet - INFO - Epoch [1][100/1576]\tlr: 4.975e-02, eta: 0:07:23, time: 0.123, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0003, top-1: 100.0000, loss: 0.0003\n",
      "2023-06-05 04:41:04,737 - mmdet - INFO - Epoch [1][150/1576]\tlr: 7.463e-02, eta: 0:06:55, time: 0.124, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:41:10,908 - mmdet - INFO - Epoch [1][200/1576]\tlr: 9.950e-02, eta: 0:06:37, time: 0.123, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:41:17,107 - mmdet - INFO - Epoch [1][250/1576]\tlr: 1.000e-01, eta: 0:06:24, time: 0.124, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:41:23,303 - mmdet - INFO - Epoch [1][300/1576]\tlr: 1.000e-01, eta: 0:06:13, time: 0.124, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:41:29,527 - mmdet - INFO - Epoch [1][350/1576]\tlr: 1.000e-01, eta: 0:06:04, time: 0.124, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:41:35,740 - mmdet - INFO - Epoch [1][400/1576]\tlr: 1.000e-01, eta: 0:05:56, time: 0.124, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:41:41,980 - mmdet - INFO - Epoch [1][450/1576]\tlr: 1.000e-01, eta: 0:05:48, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:41:48,189 - mmdet - INFO - Epoch [1][500/1576]\tlr: 1.000e-01, eta: 0:05:40, time: 0.124, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:41:54,409 - mmdet - INFO - Epoch [1][550/1576]\tlr: 1.000e-01, eta: 0:05:33, time: 0.124, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:42:00,623 - mmdet - INFO - Epoch [1][600/1576]\tlr: 1.000e-01, eta: 0:05:25, time: 0.124, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:42:06,830 - mmdet - INFO - Epoch [1][650/1576]\tlr: 1.000e-01, eta: 0:05:18, time: 0.124, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:42:13,052 - mmdet - INFO - Epoch [1][700/1576]\tlr: 1.000e-01, eta: 0:05:11, time: 0.124, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:42:19,293 - mmdet - INFO - Epoch [1][750/1576]\tlr: 1.000e-01, eta: 0:05:05, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:42:25,540 - mmdet - INFO - Epoch [1][800/1576]\tlr: 1.000e-01, eta: 0:04:58, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:42:31,792 - mmdet - INFO - Epoch [1][850/1576]\tlr: 1.000e-01, eta: 0:04:51, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:42:38,053 - mmdet - INFO - Epoch [1][900/1576]\tlr: 1.000e-01, eta: 0:04:45, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:42:44,300 - mmdet - INFO - Epoch [1][950/1576]\tlr: 1.000e-01, eta: 0:04:38, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:42:50,559 - mmdet - INFO - Epoch [1][1000/1576]\tlr: 1.000e-01, eta: 0:04:32, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:42:56,810 - mmdet - INFO - Epoch [1][1050/1576]\tlr: 1.000e-01, eta: 0:04:25, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-06-05 04:43:03,059 - mmdet - INFO - Epoch [1][1100/1576]\tlr: 1.000e-01, eta: 0:04:19, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:43:09,312 - mmdet - INFO - Epoch [1][1150/1576]\tlr: 1.000e-01, eta: 0:04:12, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:43:15,559 - mmdet - INFO - Epoch [1][1200/1576]\tlr: 1.000e-01, eta: 0:04:06, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:43:21,804 - mmdet - INFO - Epoch [1][1250/1576]\tlr: 1.000e-01, eta: 0:04:00, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:43:28,071 - mmdet - INFO - Epoch [1][1300/1576]\tlr: 1.000e-01, eta: 0:03:53, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:43:34,336 - mmdet - INFO - Epoch [1][1350/1576]\tlr: 1.000e-01, eta: 0:03:47, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:43:40,683 - mmdet - INFO - Epoch [1][1400/1576]\tlr: 1.000e-01, eta: 0:03:41, time: 0.127, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:43:46,940 - mmdet - INFO - Epoch [1][1450/1576]\tlr: 1.000e-01, eta: 0:03:34, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:43:53,217 - mmdet - INFO - Epoch [1][1500/1576]\tlr: 1.000e-01, eta: 0:03:28, time: 0.126, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:43:59,540 - mmdet - INFO - Epoch [1][1550/1576]\tlr: 1.000e-01, eta: 0:03:22, time: 0.126, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:44:02,796 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
      "2023-06-05 04:44:11,828 - mmdet - INFO - Epoch [2][50/1576]\tlr: 1.000e-02, eta: 0:03:11, time: 0.172, data_time: 0.047, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:44:18,078 - mmdet - INFO - Epoch [2][100/1576]\tlr: 1.000e-02, eta: 0:03:05, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:44:24,312 - mmdet - INFO - Epoch [2][150/1576]\tlr: 1.000e-02, eta: 0:02:58, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:44:30,579 - mmdet - INFO - Epoch [2][200/1576]\tlr: 1.000e-02, eta: 0:02:52, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:44:36,827 - mmdet - INFO - Epoch [2][250/1576]\tlr: 1.000e-02, eta: 0:02:46, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:44:43,075 - mmdet - INFO - Epoch [2][300/1576]\tlr: 1.000e-02, eta: 0:02:40, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:44:49,334 - mmdet - INFO - Epoch [2][350/1576]\tlr: 1.000e-02, eta: 0:02:33, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:44:55,605 - mmdet - INFO - Epoch [2][400/1576]\tlr: 1.000e-02, eta: 0:02:27, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:45:01,977 - mmdet - INFO - Epoch [2][450/1576]\tlr: 1.000e-02, eta: 0:02:21, time: 0.127, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:45:08,236 - mmdet - INFO - Epoch [2][500/1576]\tlr: 1.000e-02, eta: 0:02:15, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:45:14,488 - mmdet - INFO - Epoch [2][550/1576]\tlr: 1.000e-02, eta: 0:02:08, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:45:20,872 - mmdet - INFO - Epoch [2][600/1576]\tlr: 1.000e-02, eta: 0:02:02, time: 0.128, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:45:27,204 - mmdet - INFO - Epoch [2][650/1576]\tlr: 1.000e-02, eta: 0:01:56, time: 0.127, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:45:33,536 - mmdet - INFO - Epoch [2][700/1576]\tlr: 1.000e-02, eta: 0:01:50, time: 0.127, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:45:39,884 - mmdet - INFO - Epoch [2][750/1576]\tlr: 1.000e-02, eta: 0:01:43, time: 0.127, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:45:46,119 - mmdet - INFO - Epoch [2][800/1576]\tlr: 1.000e-02, eta: 0:01:37, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:45:52,471 - mmdet - INFO - Epoch [2][850/1576]\tlr: 1.000e-02, eta: 0:01:31, time: 0.127, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:45:58,736 - mmdet - INFO - Epoch [2][900/1576]\tlr: 1.000e-02, eta: 0:01:24, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:46:05,088 - mmdet - INFO - Epoch [2][950/1576]\tlr: 1.000e-02, eta: 0:01:18, time: 0.127, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:46:11,395 - mmdet - INFO - Epoch [2][1000/1576]\tlr: 1.000e-02, eta: 0:01:12, time: 0.126, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:46:17,637 - mmdet - INFO - Epoch [2][1050/1576]\tlr: 1.000e-02, eta: 0:01:06, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:46:23,979 - mmdet - INFO - Epoch [2][1100/1576]\tlr: 1.000e-02, eta: 0:00:59, time: 0.127, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:46:30,244 - mmdet - INFO - Epoch [2][1150/1576]\tlr: 1.000e-02, eta: 0:00:53, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:46:36,572 - mmdet - INFO - Epoch [2][1200/1576]\tlr: 1.000e-02, eta: 0:00:47, time: 0.127, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:46:42,884 - mmdet - INFO - Epoch [2][1250/1576]\tlr: 1.000e-02, eta: 0:00:40, time: 0.126, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:46:49,146 - mmdet - INFO - Epoch [2][1300/1576]\tlr: 1.000e-02, eta: 0:00:34, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:46:55,518 - mmdet - INFO - Epoch [2][1350/1576]\tlr: 1.000e-02, eta: 0:00:28, time: 0.127, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:47:01,828 - mmdet - INFO - Epoch [2][1400/1576]\tlr: 1.000e-02, eta: 0:00:22, time: 0.126, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:47:08,176 - mmdet - INFO - Epoch [2][1450/1576]\tlr: 1.000e-02, eta: 0:00:15, time: 0.127, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:47:14,416 - mmdet - INFO - Epoch [2][1500/1576]\tlr: 1.000e-02, eta: 0:00:09, time: 0.125, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:47:20,743 - mmdet - INFO - Epoch [2][1550/1576]\tlr: 1.000e-02, eta: 0:00:03, time: 0.127, data_time: 0.004, memory: 2942, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-06-05 04:47:24,004 - mmdet - INFO - Saving checkpoint at 2 epochs\n"
     ]
    }
   ],
   "source": [
    "from mmtrack.datasets import build_dataset\n",
    "from mmdet.apis import train_detector as train_model\n",
    "from mmtrack.models import build_reid as build_model\n",
    "\n",
    "\n",
    "model = build_model(cfg.model.reid)\n",
    "model.init_weights()\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "cfg.device='cuda'\n",
    "train_model(model, datasets, cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c2949f8",
   "metadata": {},
   "source": [
    "# Test the Tracktor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76ec0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    detector=dict(\n",
      "        type='FasterRCNN',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(0, 1, 2, 3),\n",
      "            frozen_stages=1,\n",
      "            norm_cfg=dict(type='BN', requires_grad=True),\n",
      "            norm_eval=True,\n",
      "            style='pytorch',\n",
      "            init_cfg=dict(\n",
      "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "        neck=dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            num_outs=5),\n",
      "        rpn_head=dict(\n",
      "            type='RPNHead',\n",
      "            in_channels=256,\n",
      "            feat_channels=256,\n",
      "            anchor_generator=dict(\n",
      "                type='AnchorGenerator',\n",
      "                scales=[8],\n",
      "                ratios=[0.5, 1.0, 2.0],\n",
      "                strides=[4, 8, 16, 32, 64]),\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[1.0, 1.0, 1.0, 1.0],\n",
      "                clip_border=False),\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "            loss_bbox=dict(\n",
      "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
      "                loss_weight=1.0)),\n",
      "        roi_head=dict(\n",
      "            type='StandardRoIHead',\n",
      "            bbox_roi_extractor=dict(\n",
      "                type='SingleRoIExtractor',\n",
      "                roi_layer=dict(\n",
      "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "                out_channels=256,\n",
      "                featmap_strides=[4, 8, 16, 32]),\n",
      "            bbox_head=dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=1,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2],\n",
      "                    clip_border=False),\n",
      "                reg_class_agnostic=False,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
      "        train_cfg=dict(\n",
      "            rpn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.3,\n",
      "                    min_pos_iou=0.3,\n",
      "                    match_low_quality=True,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=256,\n",
      "                    pos_fraction=0.5,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=False),\n",
      "                allowed_border=-1,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            rpn_proposal=dict(\n",
      "                nms_pre=2000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)),\n",
      "        test_cfg=dict(\n",
      "            rpn=dict(\n",
      "                nms_pre=1000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                score_thr=0.05,\n",
      "                nms=dict(type='nms', iou_threshold=0.5),\n",
      "                max_per_img=100)),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint='./tutorial_exps/detector/epoch_4.pth')),\n",
      "    type='Tracktor',\n",
      "    reid=dict(\n",
      "        type='BaseReID',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(3, ),\n",
      "            style='pytorch'),\n",
      "        neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
      "        head=dict(\n",
      "            type='LinearReIDHead',\n",
      "            num_fcs=1,\n",
      "            in_channels=2048,\n",
      "            fc_channels=1024,\n",
      "            out_channels=128,\n",
      "            num_classes=380,\n",
      "            loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
      "            loss_pairwise=dict(\n",
      "                type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
      "            norm_cfg=dict(type='BN1d'),\n",
      "            act_cfg=dict(type='ReLU')),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained', checkpoint='./tutorial_exps/reid/epoch_2.pth')),\n",
      "    motion=dict(\n",
      "        type='CameraMotionCompensation',\n",
      "        warp_mode='cv2.MOTION_EUCLIDEAN',\n",
      "        num_iters=100,\n",
      "        stop_eps=1e-05),\n",
      "    tracker=dict(\n",
      "        type='TracktorTracker',\n",
      "        obj_score_thr=0.5,\n",
      "        regression=dict(\n",
      "            obj_score_thr=0.5,\n",
      "            nms=dict(type='nms', iou_threshold=0.6),\n",
      "            match_iou_thr=0.3),\n",
      "        reid=dict(\n",
      "            num_samples=10,\n",
      "            img_scale=(256, 128),\n",
      "            img_norm_cfg=None,\n",
      "            match_score_thr=2.0,\n",
      "            match_iou_thr=0.2),\n",
      "        momentums=None,\n",
      "        num_frames_retain=10))\n",
      "dataset_type = 'MOTChallengeDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "    dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
      "    dict(\n",
      "        type='SeqResize',\n",
      "        img_scale=(1088, 1088),\n",
      "        share_params=True,\n",
      "        ratio_range=(0.8, 1.2),\n",
      "        keep_ratio=True,\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
      "    dict(\n",
      "        type='SeqRandomCrop',\n",
      "        share_params=False,\n",
      "        crop_size=(1088, 1088),\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='SeqNormalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='SeqPad', size_divisor=32),\n",
      "    dict(type='MatchInstances', skip_nomatch=True),\n",
      "    dict(\n",
      "        type='VideoCollect',\n",
      "        keys=[\n",
      "            'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
      "            'gt_instance_ids'\n",
      "        ]),\n",
      "    dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1088, 1088),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='VideoCollect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data_root = 'data/MOT17_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        visibility_thr=-1,\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        ref_img_sampler=dict(\n",
      "            num_ref_imgs=1,\n",
      "            frame_range=10,\n",
      "            filter_key_img=True,\n",
      "            method='uniform'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "            dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
      "            dict(\n",
      "                type='SeqResize',\n",
      "                img_scale=(1088, 1088),\n",
      "                share_params=True,\n",
      "                ratio_range=(0.8, 1.2),\n",
      "                keep_ratio=True,\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
      "            dict(\n",
      "                type='SeqRandomCrop',\n",
      "                share_params=False,\n",
      "                crop_size=(1088, 1088),\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='SeqNormalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='SeqPad', size_divisor=32),\n",
      "            dict(type='MatchInstances', skip_nomatch=True),\n",
      "            dict(\n",
      "                type='VideoCollect',\n",
      "                keys=[\n",
      "                    'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
      "                    'gt_instance_ids'\n",
      "                ]),\n",
      "            dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        ref_img_sampler=None,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='VideoCollect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        ref_img_sampler=None,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='VideoCollect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        test_mode=True))\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=100,\n",
      "    warmup_ratio=0.01,\n",
      "    step=[3])\n",
      "total_epochs = 4\n",
      "evaluation = dict(metric=['bbox', 'track'], interval=1)\n",
      "search_metrics = ['MOTA', 'IDF1', 'FN', 'FP', 'IDs', 'MT', 'ML']\n",
      "work_dir = './tutorial_exps'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/mot/tracktor/tracktor_faster-rcnn_r50_fpn_4e_mot17-private-half.py')\n",
    "cfg.data_root = 'data/MOT17_tiny/'\n",
    "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "cfg.model.detector.init_cfg.checkpoint = './tutorial_exps/detector/epoch_4.pth'\n",
    "cfg.model.reid.init_cfg.checkpoint = './tutorial_exps/reid/epoch_2.pth'\n",
    "\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.data.test.test_mode = True\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b9ed9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 04:54:38,363 - mmcv - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/detector/epoch_4.pth'}\n",
      "2023-06-05 04:54:38,364 - mmcv - INFO - load model from: ./tutorial_exps/detector/epoch_4.pth\n",
      "2023-06-05 04:54:38,364 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/detector/epoch_4.pth\n",
      "2023-06-05 04:54:38,541 - mmcv - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/reid/epoch_2.pth'}\n",
      "2023-06-05 04:54:38,542 - mmcv - INFO - load model from: ./tutorial_exps/reid/epoch_2.pth\n",
      "2023-06-05 04:54:38,542 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/reid/epoch_2.pth\n",
      "2023-06-05 04:54:38,663 - mmcv - INFO - \n",
      "detector.backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,664 - mmcv - INFO - \n",
      "detector.backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,664 - mmcv - INFO - \n",
      "detector.backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,665 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,665 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,666 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,666 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,667 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,667 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,667 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,668 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,668 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,669 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,669 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,670 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,671 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,671 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,671 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,672 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,672 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,672 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,673 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,674 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,674 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,675 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,675 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,675 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,676 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,676 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,676 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,677 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,678 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,678 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,679 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,679 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,680 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,680 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,680 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,681 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,681 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,681 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,682 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,682 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,682 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,683 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,683 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,684 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,684 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,685 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,685 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,686 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,687 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,688 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,688 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,689 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,689 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,690 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,690 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,691 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,691 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,692 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,692 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,693 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,693 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,693 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,694 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,694 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,695 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,695 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,696 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,696 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,696 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,697 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,697 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,698 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,698 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,699 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,699 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,700 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,700 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,700 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,701 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,701 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,702 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,702 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,703 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,703 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,704 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,705 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,705 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,705 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,706 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,706 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,706 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,707 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,707 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,707 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,709 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,709 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,709 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,710 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,710 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,711 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,712 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,712 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,713 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,713 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,714 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,714 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,715 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,715 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,716 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,716 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,717 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,717 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,717 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,718 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,719 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,719 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,720 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,720 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,720 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,721 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,722 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,722 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,723 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,723 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,723 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,724 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,724 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,724 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,725 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,725 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,726 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,726 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,726 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,727 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,727 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,727 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,729 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,729 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,730 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,731 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,731 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,732 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,732 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,733 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,733 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,733 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,734 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,734 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,735 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,735 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,735 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,736 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,736 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,736 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,737 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,737 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,738 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,739 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.0.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,740 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,740 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.1.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,740 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,741 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.2.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,741 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,742 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.3.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,743 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,743 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.0.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,743 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,744 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.1.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,744 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,745 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.2.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,745 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,746 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.3.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,746 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,747 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,747 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,748 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_cls.bias - torch.Size([3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,748 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,749 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_reg.bias - torch.Size([12]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,749 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_cls.weight - torch.Size([2, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,749 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_cls.bias - torch.Size([2]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,750 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_reg.weight - torch.Size([4, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,750 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_reg.bias - torch.Size([4]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,751 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,751 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,752 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,752 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2023-06-05 04:54:38,753 - mmcv - INFO - \n",
      "reid.backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,753 - mmcv - INFO - \n",
      "reid.backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,754 - mmcv - INFO - \n",
      "reid.backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,754 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,755 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,755 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,755 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,756 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,756 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,756 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,757 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,757 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,758 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,758 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,758 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,759 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,762 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,762 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,763 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,763 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,764 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,764 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,765 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,765 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,765 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,766 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,766 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,767 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,767 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,768 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,768 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,768 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,769 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,769 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,769 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,770 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,770 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,771 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,773 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,774 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,774 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,775 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,775 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,775 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,776 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,776 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,777 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,777 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,778 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,779 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,780 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,780 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,780 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,781 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,782 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,782 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,782 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,783 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,783 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,784 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,784 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,784 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,785 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,785 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,787 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,787 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,788 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,788 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,789 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,789 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,789 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,790 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,790 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,790 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,791 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,791 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,792 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,792 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,792 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,793 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,793 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,794 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,794 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,795 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,795 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,796 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,796 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,797 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,797 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,797 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,798 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,799 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,800 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,800 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,800 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,801 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,801 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,802 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,802 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,803 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,803 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,803 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,804 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,804 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,805 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,805 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,806 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,806 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,808 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,809 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,810 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,810 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,811 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,811 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,812 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,812 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,812 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,813 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,813 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,814 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,814 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,815 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,815 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,816 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,816 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,816 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,817 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,817 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,818 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,822 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,822 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,823 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,823 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,824 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,824 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,825 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,825 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,826 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,826 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,827 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,827 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,827 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,828 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,828 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,830 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,831 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,831 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,832 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,832 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,832 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,833 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,834 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,834 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,834 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,835 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,836 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,836 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,836 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,837 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,837 - mmcv - INFO - \n",
      "reid.head.fcs.0.fc.weight - torch.Size([1024, 2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,838 - mmcv - INFO - \n",
      "reid.head.fcs.0.fc.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,838 - mmcv - INFO - \n",
      "reid.head.fcs.0.bn.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,838 - mmcv - INFO - \n",
      "reid.head.fcs.0.bn.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,839 - mmcv - INFO - \n",
      "reid.head.fc_out.weight - torch.Size([128, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,839 - mmcv - INFO - \n",
      "reid.head.fc_out.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,839 - mmcv - INFO - \n",
      "reid.head.bn.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,840 - mmcv - INFO - \n",
      "reid.head.bn.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,840 - mmcv - INFO - \n",
      "reid.head.classifier.weight - torch.Size([380, 128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2023-06-05 04:54:38,841 - mmcv - INFO - \n",
      "reid.head.classifier.bias - torch.Size([380]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The model doesn't have classes\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 823/823, 4.1 task/s, elapsed: 199s, ETA:     0sEvaluate CLEAR MOT results.\n",
      "\n",
      "Eval Config:\n",
      "USE_PARALLEL         : False                         \n",
      "NUM_PARALLEL_CORES   : 8                             \n",
      "BREAK_ON_ERROR       : True                          \n",
      "RETURN_ON_ERROR      : False                         \n",
      "LOG_ON_ERROR         : /home/nimesh/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/error_log.txt\n",
      "PRINT_RESULTS        : True                          \n",
      "PRINT_ONLY_COMBINED  : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "TIME_PROGRESS        : True                          \n",
      "DISPLAY_LESS_PROGRESS : True                          \n",
      "OUTPUT_SUMMARY       : True                          \n",
      "OUTPUT_EMPTY_CLASSES : True                          \n",
      "OUTPUT_DETAILED      : True                          \n",
      "PLOT_CURVES          : True                          \n",
      "\n",
      "MotChallenge2DBox Config:\n",
      "GT_FOLDER            : /tmp/tmp73qadc5u              \n",
      "TRACKERS_FOLDER      : /tmp/tmpx2hvwnqa              \n",
      "OUTPUT_FOLDER        : None                          \n",
      "TRACKERS_TO_EVAL     : ['track']                     \n",
      "CLASSES_TO_EVAL      : ['pedestrian']                \n",
      "BENCHMARK            : MOT17                         \n",
      "SPLIT_TO_EVAL        : train                         \n",
      "INPUT_AS_ZIP         : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "DO_PREPROC           : True                          \n",
      "TRACKER_SUB_FOLDER   :                               \n",
      "OUTPUT_SUB_FOLDER    :                               \n",
      "TRACKER_DISPLAY_NAMES : None                          \n",
      "SEQMAP_FOLDER        : None                          \n",
      "SEQMAP_FILE          : /tmp/tmpx2hvwnqa/videoseq.txt \n",
      "SEQ_INFO             : None                          \n",
      "GT_LOC_FORMAT        : {gt_folder}/{seq}/gt/gt_half-val.txt\n",
      "SKIP_SPLIT_FOL       : True                          \n",
      "\n",
      "Evaluating 1 tracker(s) on 2 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, Count\n",
      "\n",
      "\n",
      "Evaluating track\n",
      "\n",
      "1 eval_sequence(MOT17-02-FRCNN, track)                                   0.3629 sec\n",
      "2 eval_sequence(MOT17-04-FRCNN, track)                                   0.7287 sec\n",
      "\n",
      "All sequences for track finished in 1.09 seconds\n",
      "\n",
      "HOTA: track-pedestrian             HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      OWTA      HOTA(0)   LocA(0)   HOTALocA(0)\n",
      "MOT17-02-FRCNN                     32.077    39.08     27.091    43.32     69.458    28.106    80.481    80.034    33.972    41.432    71.361    29.566    \n",
      "MOT17-04-FRCNN                     64.529    65.23     64.538    69.35     82.427    67.923    84.275    84.969    66.772    77.299    82.132    63.487    \n",
      "COMBINED                           56.751    57.327    57.074    61.799    79.412    60.073    83.704    83.92     59.181    68.771    79.677    54.794    \n",
      "\n",
      "Count: track-pedestrian            Dets      GT_Dets   IDs       GT_IDs    \n",
      "MOT17-02-FRCNN                     6162      9880      323       53        \n",
      "MOT17-04-FRCNN                     20342     24178     158       69        \n",
      "COMBINED                           26504     34058     481       122       \n",
      "                IDF1   IDP   IDR  Rcll  Prcn  GT MT PT ML   FP   FN IDs   FM  MOTA  MOTP IDt IDa IDm      HOTA\n",
      "MOT17-04-FRCNN 77.1% 84.4% 71.0% 81.5% 96.9%  69 47 18  4  637 4473  86  142 78.5% 0.171  22  67   4  0.645287\n",
      "MOT17-02-FRCNN 36.5% 47.5% 29.6% 51.6% 82.8%  53 10 31 12 1061 4779 189  207 39.0% 0.225  20 168   3  0.320771\n",
      "OVERALL        66.4% 75.8% 59.0% 72.8% 93.6% 122 57 49 16 1698 9252 275  349 67.0% 0.182  42 235   7  0.567509\n",
      "{'IDF1': 0.664, 'IDP': 0.758, 'IDR': 0.59, 'Rcll': 0.728, 'Prcn': 0.936, 'GT': 122, 'MT': 57, 'PT': 49, 'ML': 16, 'FP': 1698, 'FN': 9252, 'IDs': 275, 'FM': 349, 'MOTA': 0.67, 'MOTP': 0.182, 'IDt': 42, 'IDa': 235, 'IDm': 7, 'HOTA': 0.568}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mmtrack.datasets import build_dataloader\n",
    "from mmtrack.apis import init_model\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmtrack.apis import single_gpu_test\n",
    "from mmtrack.datasets import build_dataset\n",
    "\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    samples_per_gpu=1,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    dist=False,\n",
    "    shuffle=False)\n",
    "\n",
    "# build the model and load checkpoint\n",
    "model = init_model(cfg)\n",
    "\n",
    "model = MMDataParallel(model, device_ids=cfg.gpu_ids)\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_kwargs = cfg.get('evaluation', {}).copy()\n",
    "# hard-code way to remove EvalHook args\n",
    "eval_hook_args = [\n",
    "    'interval', 'tmpdir', 'start', 'gpu_collect', 'save_best',\n",
    "    'rule', 'by_epoch'\n",
    "]\n",
    "for key in eval_hook_args:\n",
    "    eval_kwargs.pop(key, None)\n",
    "eval_kwargs.update(dict(metric=['track']))\n",
    "metric = dataset.evaluate(outputs, **eval_kwargs)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fda8850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
